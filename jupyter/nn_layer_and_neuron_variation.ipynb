{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/thu-soccer/project/blob/master/colab/colab_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FtJth4hT577a",
    "outputId": "ce296e87-fcd1-4261-8057-6daacd747370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19781 train examples\n",
      "1042 test examples\n",
      "6681 train examples\n",
      "352 test examples\n",
      "6681 train examples\n",
      "352 test examples\n",
      "6646 train examples\n",
      "350 test examples\n",
      "6646 train examples\n",
      "350 test examples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_core.estimator import inputs\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from  IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "\n",
    "def normalize_and_encode(dataframe):\n",
    "    column_names_to_not_normalize = ['result']\n",
    "    column_names_to_normalize = [x for x in list(dataframe) if x not in column_names_to_not_normalize ]\n",
    "    x = dataframe[column_names_to_normalize].values\n",
    "    x_scaled = preprocessing.normalize(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = dataframe.index)\n",
    "    dataframe[column_names_to_normalize] = df_temp\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit([ \"H\", \"A\", \"D\"])\n",
    "    dataframe.loc[:,['result']]=le.transform(dataframe['result'])\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def get_X_and_y(dataframe):\n",
    "    X = dataframe.drop(columns=['result']).values\n",
    "    y = dataframe[['result']].values\n",
    "    return X,y\n",
    "\n",
    "df01 = pd.read_csv('../data/sliding01.csv', sep=',', index_col=0)\n",
    "df02 = pd.read_csv('../data/sliding02_shots.csv', sep=',', index_col=0)\n",
    "df03 = pd.read_csv('../data/sliding03_shots_extra.csv', sep=',', index_col=0)\n",
    "df04 = pd.read_csv('../data/sliding04_shots_and_possession.csv', sep=',', index_col=0)\n",
    "df05 = pd.read_csv('../data/sliding05_shots_and_possession_extra.csv', sep=',', index_col=0)\n",
    "\n",
    "n01 = normalize_and_encode(df01)\n",
    "n02 = normalize_and_encode(df02)\n",
    "n03 = normalize_and_encode(df03)\n",
    "n04 = normalize_and_encode(df04)\n",
    "n05 = normalize_and_encode(df05)\n",
    "\n",
    "train01, test01 = train_test_split(n01, test_size=0.05)\n",
    "print(len(train01), 'train examples')\n",
    "print(len(test01), 'test examples')\n",
    "\n",
    "train02, test02 = train_test_split(n02, test_size=0.05)\n",
    "print(len(train02), 'train examples')\n",
    "print(len(test02), 'test examples')\n",
    "\n",
    "train03, test03 = train_test_split(n03, test_size=0.05)\n",
    "print(len(train03), 'train examples')\n",
    "print(len(test03), 'test examples')\n",
    "\n",
    "train04, test04 = train_test_split(n04, test_size=0.05)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "train05, test05 = train_test_split(n05, test_size=0.05)\n",
    "print(len(train04), 'train examples')\n",
    "print(len(test04), 'test examples')\n",
    "\n",
    "train_X01,train_y01 = get_X_and_y(train01)\n",
    "train_X02,train_y02 = get_X_and_y(train02)\n",
    "train_X03,train_y03 = get_X_and_y(train03)\n",
    "train_X04,train_y04 = get_X_and_y(train04)\n",
    "train_X05,train_y05 = get_X_and_y(train05)\n",
    "\n",
    "test_X01,test_y01 = get_X_and_y(test01)\n",
    "test_X02,test_y02 = get_X_and_y(test02)\n",
    "test_X03,test_y03 = get_X_and_y(test03)\n",
    "test_X04,test_y04 = get_X_and_y(test04)\n",
    "test_X05,test_y05 = get_X_and_y(test05)\n",
    "\n",
    "\n",
    "#Many models train better if you gradually reduce the learning rate during training. Use optimizers.schedules to reduce the learning rate over time:\n",
    "#The code sets a schedules.InverseTimeDecay to hyperbolically decrease the learning rate to 1/2 of the base rate at 1000 epochs, 1/3 at 2000 epochs and so on.\n",
    "\n",
    "def get_lr_schedule(train, batch_size):\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    decay_steps=(len(train)//batch_size)*1000,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "    return lr_schedule\n",
    "\n",
    "def get_optimizer(train, batch_size):\n",
    "    return tf.keras.optimizers.Adam(get_lr_schedule(train, batch_size))\n",
    "\n",
    "\n",
    "#Each model in this tutorial will use the same training configuration. So set these up in a reusable way, starting with the list of callbacks.\n",
    "#The training for this tutorial runs for many short epochs. To reduce the logging noise use the tfdocs.EpochDots which simply a . for each epoch and, and a full set of metrics every 100 epochs.\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "        tfdocs.modeling.EpochDots(),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200),\n",
    "        #tf.keras.callbacks.TensorBoard(logdir/name), # Jupyter Notebook\n",
    "        #tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1) # Google Colab\n",
    "      ]\n",
    "\n",
    "def compile_and_fit(model, name, X, y, validation_split, batch_size, optimizer=None, max_epochs=1000):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer(X, batch_size)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "     \n",
    "    history = model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        validation_split=validation_split,\n",
    "        batch_size=batch_size,\n",
    "#        steps_per_epoch = 50, # (len(train_X01)//batch_size,\n",
    "        epochs=max_epochs,\n",
    "        callbacks=get_callbacks(name),\n",
    "        verbose=0)\n",
    "    \n",
    "    model.save(\"../model/%s.h5\" %name) \n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_history(model_history):\n",
    "\tplt.plot(model_history.history['accuracy'])\n",
    "\tplt.plot(model_history.history['val_accuracy'])\n",
    "\tplt.title(\"%s accuracy\" %model_history)\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t\n",
    "\tplt.plot(model_history.history['loss'])\n",
    "\tplt.plot(model_history.history['val_loss'])\n",
    "\tplt.title(\"%s loss\" %model_history)\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "C5oCSP7gaQ9y",
    "outputId": "6e0a4bc2-e646-4474-bad8-bd213594e680"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.049957</td>\n",
       "      <td>0.165301</td>\n",
       "      <td>0.330601</td>\n",
       "      <td>0.183667</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.514268</td>\n",
       "      <td>0.367334</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.073467</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>0.293868</td>\n",
       "      <td>0.514268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.553931</td>\n",
       "      <td>0.415448</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.103862</td>\n",
       "      <td>0.484690</td>\n",
       "      <td>0.415448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.105407</td>\n",
       "      <td>0.195198</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.390396</td>\n",
       "      <td>0.312317</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.156158</td>\n",
       "      <td>0.078079</td>\n",
       "      <td>0.585594</td>\n",
       "      <td>0.507514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068789</td>\n",
       "      <td>0.117049</td>\n",
       "      <td>0.155945</td>\n",
       "      <td>0.180075</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.072030</td>\n",
       "      <td>0.648271</td>\n",
       "      <td>0.396166</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>0.144060</td>\n",
       "      <td>0.360151</td>\n",
       "      <td>0.396166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.108097</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.102949</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.205899</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.463272</td>\n",
       "      <td>0.051475</td>\n",
       "      <td>0.308848</td>\n",
       "      <td>0.154424</td>\n",
       "      <td>0.360322</td>\n",
       "      <td>0.514746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20818</td>\n",
       "      <td>2</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.097521</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.162536</td>\n",
       "      <td>0.260057</td>\n",
       "      <td>0.487607</td>\n",
       "      <td>0.065014</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.130029</td>\n",
       "      <td>0.325071</td>\n",
       "      <td>0.682650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20819</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>0.110696</td>\n",
       "      <td>0.113771</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.584228</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.153744</td>\n",
       "      <td>0.215242</td>\n",
       "      <td>0.645726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20820</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073697</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.163770</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>0.368484</td>\n",
       "      <td>0.204713</td>\n",
       "      <td>0.081885</td>\n",
       "      <td>0.122828</td>\n",
       "      <td>0.614139</td>\n",
       "      <td>0.368484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20821</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044350</td>\n",
       "      <td>0.175065</td>\n",
       "      <td>0.300111</td>\n",
       "      <td>0.066691</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.166729</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.133383</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>0.533532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20822</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055791</td>\n",
       "      <td>0.140313</td>\n",
       "      <td>0.175391</td>\n",
       "      <td>0.200447</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.100223</td>\n",
       "      <td>0.334078</td>\n",
       "      <td>0.267263</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>0.167039</td>\n",
       "      <td>0.467709</td>\n",
       "      <td>0.668156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20823 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0           2   0.049957   0.165301   0.330601   0.183667    0.110200   \n",
       "1           1   0.077897   0.103862   0.121172   0.103862    0.138483   \n",
       "2           1   0.109311   0.117119   0.105407   0.195198    0.078079   \n",
       "3           0   0.068789   0.117049   0.155945   0.180075    0.108045   \n",
       "4           2   0.108097   0.154424   0.205899   0.102949    0.205899   \n",
       "...       ...        ...        ...        ...        ...         ...   \n",
       "20818       2   0.162536   0.123527   0.055262   0.097521    0.065014   \n",
       "20819       2   0.061498   0.110696   0.113771   0.092247    0.092247   \n",
       "20820       2   0.073697   0.153535   0.184242   0.122828    0.163770   \n",
       "20821       2   0.044350   0.175065   0.300111   0.066691    0.100037   \n",
       "20822       2   0.055791   0.140313   0.175391   0.200447    0.033408   \n",
       "\n",
       "       home-losses  home-goals  home-opposition-goals  away-wins  away-draws  \\\n",
       "0         0.073467    0.514268               0.367334   0.073467    0.073467   \n",
       "1         0.103862    0.553931               0.415448   0.138483    0.103862   \n",
       "2         0.117119    0.390396               0.312317   0.156158    0.156158   \n",
       "3         0.072030    0.648271               0.396166   0.108045    0.108045   \n",
       "4         0.205899    0.308848               0.463272   0.051475    0.308848   \n",
       "...            ...         ...                    ...        ...         ...   \n",
       "20818     0.162536    0.260057               0.487607   0.065014    0.130029   \n",
       "20819     0.122995    0.307489               0.584228   0.030749    0.122995   \n",
       "20820     0.122828    0.409426               0.368484   0.204713    0.081885   \n",
       "20821     0.166729    0.400149               0.466840   0.100037    0.100037   \n",
       "20822     0.100223    0.334078               0.267263   0.133631    0.033408   \n",
       "\n",
       "       away-losses  away-goals  away-opposition-goals  \n",
       "0         0.220401    0.293868               0.514268  \n",
       "1         0.103862    0.484690               0.415448  \n",
       "2         0.078079    0.585594               0.507514  \n",
       "3         0.144060    0.360151               0.396166  \n",
       "4         0.154424    0.360322               0.514746  \n",
       "...            ...         ...                    ...  \n",
       "20818     0.130029    0.325071               0.682650  \n",
       "20819     0.153744    0.215242               0.645726  \n",
       "20820     0.122828    0.614139               0.368484  \n",
       "20821     0.133383    0.366803               0.533532  \n",
       "20822     0.167039    0.467709               0.668156  \n",
       "\n",
       "[20823 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "UCnuh-duaSip",
    "outputId": "9ec7f29c-b38b-46c6-a6bb-d1904d8dfb17"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039230</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488587</td>\n",
       "      <td>0.238944</td>\n",
       "      <td>0.417260</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.028531</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574178</td>\n",
       "      <td>0.278173</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059110</td>\n",
       "      <td>0.495044</td>\n",
       "      <td>0.236439</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384213</td>\n",
       "      <td>0.162552</td>\n",
       "      <td>0.321409</td>\n",
       "      <td>0.132997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451585</td>\n",
       "      <td>0.218266</td>\n",
       "      <td>0.466638</td>\n",
       "      <td>0.210740</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504270</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.376321</td>\n",
       "      <td>0.173108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560339</td>\n",
       "      <td>0.259592</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.117133</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535013</td>\n",
       "      <td>0.300747</td>\n",
       "      <td>0.357730</td>\n",
       "      <td>0.183614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546982</td>\n",
       "      <td>0.244613</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.105320</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485829</td>\n",
       "      <td>0.234421</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.324626</td>\n",
       "      <td>0.174487</td>\n",
       "      <td>0.474766</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085214</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>0.235354</td>\n",
       "      <td>0.454477</td>\n",
       "      <td>0.263759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.443238</td>\n",
       "      <td>0.234070</td>\n",
       "      <td>0.458179</td>\n",
       "      <td>0.229089</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.517941</td>\n",
       "      <td>0.273911</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.129485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019044</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016928</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516293</td>\n",
       "      <td>0.249683</td>\n",
       "      <td>0.389336</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.021160</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063479</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355481</td>\n",
       "      <td>0.181972</td>\n",
       "      <td>0.499366</td>\n",
       "      <td>0.236987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.491416</td>\n",
       "      <td>0.245708</td>\n",
       "      <td>0.392341</td>\n",
       "      <td>0.198152</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067372</td>\n",
       "      <td>0.408193</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>0.483490</td>\n",
       "      <td>0.214004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039168</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411259</td>\n",
       "      <td>0.254589</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.211505</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050918</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446510</td>\n",
       "      <td>0.246755</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.180171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006332   \n",
       "4          2   0.004077   0.020384   0.064551   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017929   0.018427   0.014941    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019044   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023501    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039230               0.057061    0.488587   \n",
       "1        0.022166    0.029555               0.059110    0.495044   \n",
       "2        0.015053    0.037632               0.056448    0.451585   \n",
       "3        0.009497    0.069647               0.037989    0.560339   \n",
       "4        0.003397    0.050961               0.027179    0.546982   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048694    0.324626   \n",
       "7029     0.024901    0.044822               0.104584    0.443238   \n",
       "7030     0.016928    0.033855               0.033855    0.516293   \n",
       "7031     0.019815    0.047556               0.055483    0.491416   \n",
       "7032     0.011750    0.039168               0.031334    0.411259   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238944               0.417260   \n",
       "1                 0.236439               0.557848   \n",
       "2                 0.218266               0.466638   \n",
       "3                 0.259592               0.234266   \n",
       "4                 0.244613               0.251408   \n",
       "...                    ...                    ...   \n",
       "7028              0.174487               0.474766   \n",
       "7029              0.234070               0.458179   \n",
       "7030              0.249683               0.389336   \n",
       "7031              0.245708               0.392341   \n",
       "7032              0.254589               0.493511   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189015   0.028531    0.007133     0.000000   \n",
       "1                            0.284465   0.011083    0.011083     0.014777   \n",
       "2                            0.210740   0.007526    0.007526     0.022579   \n",
       "3                            0.117133   0.018995    0.009497     0.003166   \n",
       "4                            0.105320   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243470   0.008116    0.016231     0.016231   \n",
       "7029                         0.229089   0.004980    0.019921     0.024901   \n",
       "7030                         0.211596   0.021160    0.008464     0.012696   \n",
       "7031                         0.198152   0.011889    0.011889     0.015852   \n",
       "7032                         0.211505   0.011750    0.007834     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574178              0.278173   \n",
       "1       0.040638               0.066498    0.384213              0.162552   \n",
       "2       0.041395               0.056448    0.504270              0.222029   \n",
       "3       0.060149               0.025326    0.535013              0.300747   \n",
       "4       0.033974               0.057756    0.485829              0.234421   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085214    0.482881              0.235354   \n",
       "7029    0.034861               0.104584    0.517941              0.273911   \n",
       "7030    0.063479               0.038087    0.355481              0.181972   \n",
       "7031    0.043593               0.067372    0.408193              0.210041   \n",
       "7032    0.050918               0.074418    0.446510              0.246755   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \n",
       "0                  0.256775                         0.106990  \n",
       "1                  0.321409                         0.132997  \n",
       "2                  0.376321                         0.173108  \n",
       "3                  0.357730                         0.183614  \n",
       "4                  0.455252                         0.234421  \n",
       "...                     ...                              ...  \n",
       "7028               0.454477                         0.263759  \n",
       "7029               0.313753                         0.129485  \n",
       "7030               0.499366                         0.236987  \n",
       "7031               0.483490                         0.214004  \n",
       "7032               0.415176                         0.180171  \n",
       "\n",
       "[7033 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "iUgEWCcJaTKx",
    "outputId": "a30e80e8-8b13-43cf-988d-0fa22e73fd94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.010699</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>0.057061</td>\n",
       "      <td>0.488583</td>\n",
       "      <td>0.238942</td>\n",
       "      <td>0.417257</td>\n",
       "      <td>0.189014</td>\n",
       "      <td>0.028530</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053495</td>\n",
       "      <td>0.021398</td>\n",
       "      <td>0.574174</td>\n",
       "      <td>0.278171</td>\n",
       "      <td>0.256774</td>\n",
       "      <td>0.106989</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009236</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>0.029555</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.495039</td>\n",
       "      <td>0.236437</td>\n",
       "      <td>0.557843</td>\n",
       "      <td>0.284463</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.384210</td>\n",
       "      <td>0.162550</td>\n",
       "      <td>0.321406</td>\n",
       "      <td>0.132996</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.451581</td>\n",
       "      <td>0.218264</td>\n",
       "      <td>0.466634</td>\n",
       "      <td>0.210738</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.041395</td>\n",
       "      <td>0.056448</td>\n",
       "      <td>0.504266</td>\n",
       "      <td>0.222028</td>\n",
       "      <td>0.376318</td>\n",
       "      <td>0.173106</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.069646</td>\n",
       "      <td>0.037989</td>\n",
       "      <td>0.560335</td>\n",
       "      <td>0.259590</td>\n",
       "      <td>0.234264</td>\n",
       "      <td>0.117132</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.060149</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>0.535009</td>\n",
       "      <td>0.300745</td>\n",
       "      <td>0.357728</td>\n",
       "      <td>0.183613</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.050961</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>0.546979</td>\n",
       "      <td>0.244612</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.485826</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.455249</td>\n",
       "      <td>0.234419</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7028</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>0.015420</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.324623</td>\n",
       "      <td>0.174485</td>\n",
       "      <td>0.474761</td>\n",
       "      <td>0.243467</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.040578</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.482876</td>\n",
       "      <td>0.235351</td>\n",
       "      <td>0.454472</td>\n",
       "      <td>0.263756</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7029</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.044821</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.443228</td>\n",
       "      <td>0.234064</td>\n",
       "      <td>0.458168</td>\n",
       "      <td>0.229084</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.104582</td>\n",
       "      <td>0.517929</td>\n",
       "      <td>0.273905</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.129482</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.004022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7030</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007617</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.019043</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.016927</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.516288</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>0.389332</td>\n",
       "      <td>0.211593</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.063478</td>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>0.181970</td>\n",
       "      <td>0.499360</td>\n",
       "      <td>0.236985</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7031</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.055482</td>\n",
       "      <td>0.491412</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>0.392337</td>\n",
       "      <td>0.198150</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>0.408189</td>\n",
       "      <td>0.210039</td>\n",
       "      <td>0.483486</td>\n",
       "      <td>0.214002</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7032</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.023500</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.411255</td>\n",
       "      <td>0.254586</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.211503</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.050917</td>\n",
       "      <td>0.074418</td>\n",
       "      <td>0.446505</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.415172</td>\n",
       "      <td>0.180169</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7033 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.012482   0.011769   0.007489   0.003566    0.010699   \n",
       "1          1   0.009236   0.012191   0.010640   0.011083    0.003694   \n",
       "2          0   0.007188   0.012795   0.015805   0.015053    0.007526   \n",
       "3          2   0.010289   0.010289   0.007281   0.015829    0.006331   \n",
       "4          2   0.004077   0.020384   0.064550   0.023782    0.006795   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "7028       2   0.020289   0.015420   0.006898   0.016231    0.008116   \n",
       "7029       2   0.009960   0.017928   0.018426   0.014940    0.009960   \n",
       "7030       2   0.007617   0.015870   0.019043   0.012696    0.012696   \n",
       "7031       2   0.005271   0.020806   0.035667   0.007926    0.011889   \n",
       "7032       2   0.006541   0.016450   0.020563   0.023500    0.003917   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.021398    0.039229               0.057061    0.488583   \n",
       "1        0.022166    0.029555               0.059109    0.495039   \n",
       "2        0.015053    0.037632               0.056448    0.451581   \n",
       "3        0.009497    0.069646               0.037989    0.560335   \n",
       "4        0.003397    0.050961               0.027179    0.546979   \n",
       "...           ...         ...                    ...         ...   \n",
       "7028     0.016231    0.040578               0.048693    0.324623   \n",
       "7029     0.024900    0.044821               0.104582    0.443228   \n",
       "7030     0.016927    0.033855               0.033855    0.516288   \n",
       "7031     0.019815    0.047556               0.055482    0.491412   \n",
       "7032     0.011750    0.039167               0.031334    0.411255   \n",
       "\n",
       "      home-shots_on_target  home-opposition_shots  \\\n",
       "0                 0.238942               0.417257   \n",
       "1                 0.236437               0.557843   \n",
       "2                 0.218264               0.466634   \n",
       "3                 0.259590               0.234264   \n",
       "4                 0.244612               0.251406   \n",
       "...                    ...                    ...   \n",
       "7028              0.174485               0.474761   \n",
       "7029              0.234064               0.458168   \n",
       "7030              0.249680               0.389332   \n",
       "7031              0.245706               0.392337   \n",
       "7032              0.254586               0.493506   \n",
       "\n",
       "      home-opposition_shots_on_target  away-wins  away-draws  away-losses  \\\n",
       "0                            0.189014   0.028530    0.007133     0.000000   \n",
       "1                            0.284463   0.011083    0.011083     0.014777   \n",
       "2                            0.210738   0.007526    0.007526     0.022579   \n",
       "3                            0.117132   0.018994    0.009497     0.003166   \n",
       "4                            0.105319   0.010192    0.006795     0.016987   \n",
       "...                               ...        ...         ...          ...   \n",
       "7028                         0.243467   0.008116    0.016231     0.016231   \n",
       "7029                         0.229084   0.004980    0.019920     0.024900   \n",
       "7030                         0.211593   0.021159    0.008464     0.012696   \n",
       "7031                         0.198150   0.011889    0.011889     0.015852   \n",
       "7032                         0.211503   0.011750    0.007833     0.019584   \n",
       "\n",
       "      away-goals  away-opposition-goals  away-shots  away-shots_on_target  \\\n",
       "0       0.053495               0.021398    0.574174              0.278171   \n",
       "1       0.040638               0.066498    0.384210              0.162550   \n",
       "2       0.041395               0.056448    0.504266              0.222028   \n",
       "3       0.060149               0.025326    0.535009              0.300745   \n",
       "4       0.033974               0.057756    0.485826              0.234419   \n",
       "...          ...                    ...         ...                   ...   \n",
       "7028    0.040578               0.085213    0.482876              0.235351   \n",
       "7029    0.034861               0.104582    0.517929              0.273905   \n",
       "7030    0.063478               0.038087    0.355477              0.181970   \n",
       "7031    0.043593               0.067371    0.408189              0.210039   \n",
       "7032    0.050917               0.074418    0.446505              0.246753   \n",
       "\n",
       "      away-opposition_shots  away-opposition_shots_on_target  \\\n",
       "0                  0.256774                         0.106989   \n",
       "1                  0.321406                         0.132996   \n",
       "2                  0.376318                         0.173106   \n",
       "3                  0.357728                         0.183613   \n",
       "4                  0.455249                         0.234419   \n",
       "...                     ...                              ...   \n",
       "7028               0.454472                         0.263756   \n",
       "7029               0.313745                         0.129482   \n",
       "7030               0.499360                         0.236985   \n",
       "7031               0.483486                         0.214002   \n",
       "7032               0.415172                         0.180169   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.001744              0.000586                       0.001616   \n",
       "1               0.001764              0.000462                       0.001884   \n",
       "2               0.001819              0.000649                       0.001699   \n",
       "3               0.001467              0.000849                       0.001583   \n",
       "4               0.001519              0.000708                       0.001423   \n",
       "...                  ...                   ...                            ...   \n",
       "7028            0.002181              0.000944                       0.002081   \n",
       "7029            0.002630              0.000954                       0.002490   \n",
       "7030            0.002047              0.000574                       0.002300   \n",
       "7031            0.001981              0.000767                       0.002002   \n",
       "7032            0.002425              0.000603                       0.001679   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.001077            0.001728   \n",
       "1                            0.000768            0.001563   \n",
       "2                            0.001008            0.001657   \n",
       "3                            0.001027            0.001780   \n",
       "4                            0.000877            0.001639   \n",
       "...                               ...                 ...   \n",
       "7028                         0.000812            0.001978   \n",
       "7029                         0.002274            0.002634   \n",
       "7030                         0.000677            0.002166   \n",
       "7031                         0.001110            0.002039   \n",
       "7032                         0.000580            0.002164   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000686                       0.001486   \n",
       "1                 0.000924                       0.001529   \n",
       "2                 0.000702                       0.001731   \n",
       "3                 0.000633                       0.001625   \n",
       "4                 0.000492                       0.001749   \n",
       "...                    ...                            ...   \n",
       "7028              0.000700                       0.002355   \n",
       "7029              0.000634                       0.002055   \n",
       "7030              0.001476                       0.002008   \n",
       "7031              0.000823                       0.001754   \n",
       "7032              0.000808                       0.001700   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000713  \n",
       "1                            0.001847  \n",
       "2                            0.001227  \n",
       "3                            0.000437  \n",
       "4                            0.000837  \n",
       "...                               ...  \n",
       "7028                         0.001311  \n",
       "7029                         0.004022  \n",
       "7030                         0.000680  \n",
       "7031                         0.001248  \n",
       "7032                         0.001618  \n",
       "\n",
       "[7033 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "tPTv1eKnaTy6",
    "outputId": "a438f9c7-fdce-4e67-a4fc-8af1bf8e89e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.143652</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.168817</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.505403</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.448781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.192540</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.375911</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.558264</td>\n",
       "      <td>0.115116</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.368780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>0.498568</td>\n",
       "      <td>0.077346</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.452578</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.145285</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.507975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.460917</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.494515</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.524963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.454281</td>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.076236</td>\n",
       "      <td>0.496054</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.493965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.436415</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>0.521801</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.410062</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.549208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6992</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.110924</td>\n",
       "      <td>0.058662</td>\n",
       "      <td>0.447961</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.522621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.129584</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.476910</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.489656</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.439734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6994</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.399757</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>0.128343</td>\n",
       "      <td>0.056808</td>\n",
       "      <td>0.496540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.568601</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.487822</td>\n",
       "      <td>0.111202</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.466840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.003670   0.003460   0.002202   0.001049    0.003146   \n",
       "1          2   0.003311   0.003311   0.002343   0.005094    0.002037   \n",
       "2          2   0.001254   0.006271   0.019859   0.007317    0.002090   \n",
       "3          0   0.002499   0.003465   0.003150   0.003150    0.003150   \n",
       "4          0   0.002715   0.003394   0.002924   0.004177    0.001044   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.005271   0.004006   0.001792   0.004217    0.002108   \n",
       "6992       2   0.002133   0.003840   0.003946   0.003200    0.002133   \n",
       "6993       2   0.001912   0.003983   0.004780   0.003186    0.003186   \n",
       "6994       2   0.001399   0.005523   0.009468   0.002104    0.003156   \n",
       "6995       2   0.001752   0.004406   0.005508   0.006294    0.001049   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.006291    0.011534               0.016777    0.143652   \n",
       "1        0.003056    0.019356               0.012225    0.192540   \n",
       "2        0.001045    0.015678               0.008362    0.168280   \n",
       "3        0.004200    0.009449               0.011549    0.107092   \n",
       "4        0.005222    0.015665               0.016709    0.130540   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.004217    0.010541               0.012650    0.084331   \n",
       "6992     0.005333    0.009599               0.022398    0.094925   \n",
       "6993     0.004249    0.008497               0.008497    0.129584   \n",
       "6994     0.005260    0.012624               0.014728    0.130447   \n",
       "6995     0.003147    0.010491               0.008393    0.110153   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.070253         0.504354               0.122681   \n",
       "1                 0.090667         0.550114               0.070292   \n",
       "2                 0.075256         0.498568               0.077346   \n",
       "3                 0.049346         0.460917               0.139640   \n",
       "4                 0.065792         0.454281               0.159781   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.045328         0.436415               0.123335   \n",
       "6992              0.050129         0.417030               0.098125   \n",
       "6993              0.062667         0.476910               0.097719   \n",
       "6994              0.065223         0.557555               0.104147   \n",
       "6995              0.068190         0.568601               0.132184   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.055573                    0.449829   0.008388   \n",
       "1                            0.036674                    0.375911   0.006112   \n",
       "2                            0.032402                    0.452578   0.002090   \n",
       "3                            0.080844                    0.494515   0.003150   \n",
       "4                            0.076236                    0.496054   0.004177   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.063249                    0.521801   0.002108   \n",
       "6992                         0.049062                    0.553551   0.001067   \n",
       "6993                         0.053108                    0.489656   0.005311   \n",
       "6994                         0.052600                    0.399757   0.003156   \n",
       "6995                         0.056650                    0.386061   0.003147   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.002097     0.000000    0.015728               0.006291    0.168817   \n",
       "1       0.003056     0.001019    0.019356               0.008150    0.172165   \n",
       "2       0.002090     0.006271    0.009407               0.018814    0.137968   \n",
       "3       0.002100     0.005250    0.009449               0.016799    0.121791   \n",
       "4       0.003133     0.003133    0.013576               0.016709    0.107565   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.004217     0.004217    0.010541               0.022137    0.125443   \n",
       "6992    0.004266     0.005333    0.007466               0.022398    0.110924   \n",
       "6993    0.002124     0.003186    0.015932               0.009559    0.089221   \n",
       "6994    0.003156     0.004208    0.011572               0.017884    0.108355   \n",
       "6995    0.002098     0.005245    0.013638               0.019932    0.119595   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.081787         0.505403               0.075496   \n",
       "1                 0.096779         0.558264               0.115116   \n",
       "2                 0.064803         0.443171               0.145285   \n",
       "3                 0.056696         0.430469               0.137540   \n",
       "4                 0.053260         0.456369               0.144117   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.061140         0.410062               0.118064   \n",
       "6992              0.058662         0.447961               0.067194   \n",
       "6993              0.045673         0.525769               0.125335   \n",
       "6994              0.055756         0.460772               0.128343   \n",
       "6995              0.066092         0.487822               0.111202   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \n",
       "0                            0.031457                    0.448781  \n",
       "1                            0.059086                    0.368780  \n",
       "2                            0.074210                    0.507975  \n",
       "3                            0.067195                    0.524963  \n",
       "4                            0.079369                    0.493965  \n",
       "...                               ...                         ...  \n",
       "6991                         0.068519                    0.549208  \n",
       "6992                         0.027731                    0.522621  \n",
       "6993                         0.059481                    0.439734  \n",
       "6994                         0.056808                    0.496540  \n",
       "6995                         0.048258                    0.466840  \n",
       "\n",
       "[6996 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "wHXHdefzaUcP",
    "outputId": "55ce72c7-6329-4541-c391-a10303b02d3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>odds-home</th>\n",
       "      <th>odds-draw</th>\n",
       "      <th>odds-away</th>\n",
       "      <th>home-wins</th>\n",
       "      <th>home-draws</th>\n",
       "      <th>home-losses</th>\n",
       "      <th>home-goals</th>\n",
       "      <th>home-opposition-goals</th>\n",
       "      <th>home-shots</th>\n",
       "      <th>home-shots_on_target</th>\n",
       "      <th>home-possession</th>\n",
       "      <th>home-opposition_shots</th>\n",
       "      <th>home-opposition_shots_on_target</th>\n",
       "      <th>home-opposition_possession</th>\n",
       "      <th>away-wins</th>\n",
       "      <th>away-draws</th>\n",
       "      <th>away-losses</th>\n",
       "      <th>away-goals</th>\n",
       "      <th>away-opposition-goals</th>\n",
       "      <th>away-shots</th>\n",
       "      <th>away-shots_on_target</th>\n",
       "      <th>away-possession</th>\n",
       "      <th>away-opposition_shots</th>\n",
       "      <th>away-opposition_shots_on_target</th>\n",
       "      <th>away-opposition_possession</th>\n",
       "      <th>home_shot_accuracy</th>\n",
       "      <th>home_shot_efficiency</th>\n",
       "      <th>home_opposition_shot_accuracy</th>\n",
       "      <th>home_opposition_shot_efficiency</th>\n",
       "      <th>away_shot_accuracy</th>\n",
       "      <th>away_shot_efficiency</th>\n",
       "      <th>away_opposition_shot_accuracy</th>\n",
       "      <th>away_opposition_shot_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.143652</td>\n",
       "      <td>0.070253</td>\n",
       "      <td>0.504354</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>0.055573</td>\n",
       "      <td>0.449829</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015728</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.168817</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.505402</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.031457</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.192540</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.070292</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.375911</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.019356</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.558263</td>\n",
       "      <td>0.115116</td>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.368780</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.015678</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.168280</td>\n",
       "      <td>0.075255</td>\n",
       "      <td>0.498567</td>\n",
       "      <td>0.077346</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>0.452578</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.018814</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.145285</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.049346</td>\n",
       "      <td>0.460917</td>\n",
       "      <td>0.139640</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.494515</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>0.056696</td>\n",
       "      <td>0.430469</td>\n",
       "      <td>0.137540</td>\n",
       "      <td>0.067195</td>\n",
       "      <td>0.524962</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.130540</td>\n",
       "      <td>0.065792</td>\n",
       "      <td>0.454280</td>\n",
       "      <td>0.159781</td>\n",
       "      <td>0.076236</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.107565</td>\n",
       "      <td>0.053260</td>\n",
       "      <td>0.456369</td>\n",
       "      <td>0.144117</td>\n",
       "      <td>0.079369</td>\n",
       "      <td>0.493965</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6991</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.084331</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0.436415</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.063249</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.022137</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.061140</td>\n",
       "      <td>0.410061</td>\n",
       "      <td>0.118064</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.549208</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6992</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.050129</td>\n",
       "      <td>0.417030</td>\n",
       "      <td>0.098125</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.553551</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>0.058661</td>\n",
       "      <td>0.447960</td>\n",
       "      <td>0.067194</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.004249</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.129583</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.476909</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.525769</td>\n",
       "      <td>0.125335</td>\n",
       "      <td>0.059481</td>\n",
       "      <td>0.439734</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6994</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.130447</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.104147</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.399756</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.017884</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.460772</td>\n",
       "      <td>0.128343</td>\n",
       "      <td>0.056807</td>\n",
       "      <td>0.496539</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6995</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.008393</td>\n",
       "      <td>0.110153</td>\n",
       "      <td>0.068190</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>0.386061</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.119595</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>0.111202</td>\n",
       "      <td>0.048258</td>\n",
       "      <td>0.466840</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6996 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      result  odds-home  odds-draw  odds-away  home-wins  home-draws  \\\n",
       "0          2   0.003670   0.003460   0.002202   0.001049    0.003146   \n",
       "1          2   0.003311   0.003311   0.002343   0.005094    0.002037   \n",
       "2          2   0.001254   0.006271   0.019859   0.007317    0.002090   \n",
       "3          0   0.002499   0.003465   0.003150   0.003150    0.003150   \n",
       "4          0   0.002715   0.003394   0.002924   0.004177    0.001044   \n",
       "...      ...        ...        ...        ...        ...         ...   \n",
       "6991       2   0.005271   0.004006   0.001792   0.004217    0.002108   \n",
       "6992       2   0.002133   0.003840   0.003946   0.003200    0.002133   \n",
       "6993       2   0.001912   0.003983   0.004780   0.003186    0.003186   \n",
       "6994       2   0.001399   0.005523   0.009468   0.002104    0.003156   \n",
       "6995       2   0.001752   0.004406   0.005508   0.006294    0.001049   \n",
       "\n",
       "      home-losses  home-goals  home-opposition-goals  home-shots  \\\n",
       "0        0.006291    0.011534               0.016777    0.143652   \n",
       "1        0.003056    0.019356               0.012225    0.192540   \n",
       "2        0.001045    0.015678               0.008362    0.168280   \n",
       "3        0.004200    0.009449               0.011549    0.107092   \n",
       "4        0.005222    0.015665               0.016709    0.130540   \n",
       "...           ...         ...                    ...         ...   \n",
       "6991     0.004217    0.010541               0.012650    0.084331   \n",
       "6992     0.005333    0.009599               0.022398    0.094925   \n",
       "6993     0.004249    0.008497               0.008497    0.129583   \n",
       "6994     0.005260    0.012624               0.014728    0.130447   \n",
       "6995     0.003147    0.010491               0.008393    0.110153   \n",
       "\n",
       "      home-shots_on_target  home-possession  home-opposition_shots  \\\n",
       "0                 0.070253         0.504354               0.122681   \n",
       "1                 0.090667         0.550114               0.070292   \n",
       "2                 0.075255         0.498567               0.077346   \n",
       "3                 0.049346         0.460917               0.139640   \n",
       "4                 0.065792         0.454280               0.159781   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.045328         0.436415               0.123335   \n",
       "6992              0.050129         0.417030               0.098125   \n",
       "6993              0.062667         0.476909               0.097719   \n",
       "6994              0.065223         0.557555               0.104147   \n",
       "6995              0.068190         0.568600               0.132184   \n",
       "\n",
       "      home-opposition_shots_on_target  home-opposition_possession  away-wins  \\\n",
       "0                            0.055573                    0.449829   0.008388   \n",
       "1                            0.036674                    0.375911   0.006112   \n",
       "2                            0.032402                    0.452578   0.002090   \n",
       "3                            0.080844                    0.494515   0.003150   \n",
       "4                            0.076236                    0.496053   0.004177   \n",
       "...                               ...                         ...        ...   \n",
       "6991                         0.063249                    0.521800   0.002108   \n",
       "6992                         0.049062                    0.553551   0.001067   \n",
       "6993                         0.053108                    0.489655   0.005311   \n",
       "6994                         0.052600                    0.399756   0.003156   \n",
       "6995                         0.056650                    0.386061   0.003147   \n",
       "\n",
       "      away-draws  away-losses  away-goals  away-opposition-goals  away-shots  \\\n",
       "0       0.002097     0.000000    0.015728               0.006291    0.168817   \n",
       "1       0.003056     0.001019    0.019356               0.008150    0.172165   \n",
       "2       0.002090     0.006271    0.009407               0.018814    0.137968   \n",
       "3       0.002100     0.005250    0.009449               0.016799    0.121791   \n",
       "4       0.003133     0.003133    0.013576               0.016709    0.107565   \n",
       "...          ...          ...         ...                    ...         ...   \n",
       "6991    0.004217     0.004217    0.010541               0.022137    0.125443   \n",
       "6992    0.004266     0.005333    0.007466               0.022398    0.110923   \n",
       "6993    0.002124     0.003186    0.015932               0.009559    0.089221   \n",
       "6994    0.003156     0.004208    0.011572               0.017884    0.108355   \n",
       "6995    0.002098     0.005245    0.013638               0.019932    0.119595   \n",
       "\n",
       "      away-shots_on_target  away-possession  away-opposition_shots  \\\n",
       "0                 0.081787         0.505402               0.075496   \n",
       "1                 0.096779         0.558263               0.115116   \n",
       "2                 0.064803         0.443171               0.145285   \n",
       "3                 0.056696         0.430469               0.137540   \n",
       "4                 0.053260         0.456369               0.144117   \n",
       "...                    ...              ...                    ...   \n",
       "6991              0.061140         0.410061               0.118064   \n",
       "6992              0.058661         0.447960               0.067194   \n",
       "6993              0.045673         0.525769               0.125335   \n",
       "6994              0.055755         0.460772               0.128343   \n",
       "6995              0.066092         0.487821               0.111202   \n",
       "\n",
       "      away-opposition_shots_on_target  away-opposition_possession  \\\n",
       "0                            0.031457                    0.448780   \n",
       "1                            0.059086                    0.368780   \n",
       "2                            0.074210                    0.507974   \n",
       "3                            0.067195                    0.524962   \n",
       "4                            0.079369                    0.493965   \n",
       "...                               ...                         ...   \n",
       "6991                         0.068519                    0.549208   \n",
       "6992                         0.027731                    0.522620   \n",
       "6993                         0.059481                    0.439734   \n",
       "6994                         0.056807                    0.496539   \n",
       "6995                         0.048258                    0.466840   \n",
       "\n",
       "      home_shot_accuracy  home_shot_efficiency  home_opposition_shot_accuracy  \\\n",
       "0               0.000513              0.000172                       0.000475   \n",
       "1               0.000480              0.000217                       0.000532   \n",
       "2               0.000467              0.000218                       0.000438   \n",
       "3               0.000484              0.000201                       0.000608   \n",
       "4               0.000526              0.000249                       0.000498   \n",
       "...                  ...                   ...                            ...   \n",
       "6991            0.000567              0.000245                       0.000541   \n",
       "6992            0.000563              0.000204                       0.000533   \n",
       "6993            0.000514              0.000144                       0.000577   \n",
       "6994            0.000526              0.000204                       0.000531   \n",
       "6995            0.000649              0.000161                       0.000450   \n",
       "\n",
       "      home_opposition_shot_efficiency  away_shot_accuracy  \\\n",
       "0                            0.000317            0.000508   \n",
       "1                            0.000340            0.000573   \n",
       "2                            0.000270            0.000491   \n",
       "3                            0.000150            0.000489   \n",
       "4                            0.000229            0.000517   \n",
       "...                               ...                 ...   \n",
       "6991                         0.000211            0.000514   \n",
       "6992                         0.000487            0.000564   \n",
       "6993                         0.000170            0.000544   \n",
       "6994                         0.000295            0.000541   \n",
       "6995                         0.000155            0.000580   \n",
       "\n",
       "      away_shot_efficiency  away_opposition_shot_accuracy  \\\n",
       "0                 0.000202                       0.000437   \n",
       "1                 0.000204                       0.000523   \n",
       "2                 0.000152                       0.000534   \n",
       "3                 0.000175                       0.000513   \n",
       "4                 0.000266                       0.000575   \n",
       "...                    ...                            ...   \n",
       "6991              0.000182                       0.000612   \n",
       "6992              0.000136                       0.000440   \n",
       "6993              0.000371                       0.000504   \n",
       "6994              0.000218                       0.000466   \n",
       "6995              0.000216                       0.000455   \n",
       "\n",
       "      away_opposition_shot_efficiency  \n",
       "0                            0.000210  \n",
       "1                            0.000141  \n",
       "2                            0.000265  \n",
       "3                            0.000262  \n",
       "4                            0.000220  \n",
       "...                               ...  \n",
       "6991                         0.000341  \n",
       "6992                         0.000861  \n",
       "6993                         0.000171  \n",
       "6994                         0.000331  \n",
       "6995                         0.000433  \n",
       "\n",
       "[6996 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCffJtvhaVPm"
   },
   "outputs": [],
   "source": [
    "####BACKUP SERGEJ####\n",
    "\n",
    "\n",
    "# Jupyter notebook\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128*8\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "model01 = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model02 = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model03 = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model04 = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model05 = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "size_histories['model01'] = compile_and_fit(model01, 'martin_model01', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02'] = compile_and_fit(model02, 'martin_model02', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03'] = compile_and_fit(model03, 'martin_model03', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04'] = compile_and_fit(model04, 'martin_model04', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05'] = compile_and_fit(model05, 'martin_model05', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Backup:\n",
    "\n",
    "## I. First Attempt:\n",
    "\n",
    "### Model01:\n",
    "\n",
    "model01 = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.9784467357591566\n",
    "Test Accuracy: 0.5393474\n",
    "### Model02:\n",
    "\n",
    "model02 = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(32, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.9985063346949491\n",
    "Test Accuracy: 0.5113636\n",
    "### Model03:\n",
    "\n",
    "model03 = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.9796081943945452\n",
    "Test Accuracy: 0.5255682\n",
    "### Model04:\n",
    "\n",
    "model04 = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(50, activation='relu'),\n",
    "  layers.Dense(30, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 0.970786578314645\n",
    "Test Accuracy: 0.5228571\n",
    "### Model05:\n",
    "\n",
    "model05 = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(66, activation='relu'),\n",
    "  layers.Dense(55, activation='relu'),\n",
    "  layers.Dense(44, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "Test Score: 1.013617993082319\n",
    "Test Accuracy: 0.52\n",
    "\n",
    "\n",
    "## II. Layer & Neuron Variantion:\n",
    "### 1 Hidden Layer:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HtHfSEgO6sUN",
    "outputId": "b7fd6a48-30f1-470e-f92b-118a7046a09a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                154       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 108       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 70        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 572\n",
      "Trainable params: 572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4105,  loss:1.0963,  val_accuracy:0.4635,  val_loss:1.0936,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5298,  loss:0.9737,  val_accuracy:0.5383,  val_loss:0.9699,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5305,  loss:0.9711,  val_accuracy:0.5378,  val_loss:0.9687,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5299,  loss:0.9704,  val_accuracy:0.5373,  val_loss:0.9685,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5314,  loss:0.9700,  val_accuracy:0.5388,  val_loss:0.9683,  \n",
      "...............................................................................................Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 21)                462       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 80)                1760      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 6,525\n",
      "Trainable params: 6,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3827,  loss:1.0940,  val_accuracy:0.4540,  val_loss:1.0856,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5312,  loss:0.9752,  val_accuracy:0.5333,  val_loss:0.9748,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5372,  loss:0.9665,  val_accuracy:0.5408,  val_loss:0.9656,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5397,  loss:0.9619,  val_accuracy:0.5303,  val_loss:0.9693,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5391,  loss:0.9617,  val_accuracy:0.5325,  val_loss:0.9666,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5438,  loss:0.9583,  val_accuracy:0.5363,  val_loss:0.9610,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5440,  loss:0.9570,  val_accuracy:0.5333,  val_loss:0.9710,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5429,  loss:0.9560,  val_accuracy:0.5378,  val_loss:0.9656,  \n",
      ".....................................................Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 29)                870       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                600       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 18        \n",
      "=================================================================\n",
      "Total params: 2,623\n",
      "Trainable params: 2,623\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3026,  loss:1.1000,  val_accuracy:0.4936,  val_loss:1.0962,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5322,  loss:0.9763,  val_accuracy:0.5393,  val_loss:0.9690,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5356,  loss:0.9688,  val_accuracy:0.5475,  val_loss:0.9632,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5346,  loss:0.9676,  val_accuracy:0.5438,  val_loss:0.9626,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5374,  loss:0.9648,  val_accuracy:0.5408,  val_loss:0.9605,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5376,  loss:0.9635,  val_accuracy:0.5415,  val_loss:0.9606,  \n",
      "......................................................................................Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 3,905\n",
      "Trainable params: 3,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.3576,  loss:1.0999,  val_accuracy:0.4429,  val_loss:1.0950,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5278,  loss:0.9838,  val_accuracy:0.5150,  val_loss:0.9953,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5342,  loss:0.9747,  val_accuracy:0.5113,  val_loss:0.9859,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5359,  loss:0.9700,  val_accuracy:0.5301,  val_loss:0.9769,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5380,  loss:0.9674,  val_accuracy:0.5241,  val_loss:0.9743,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5346,  loss:0.9688,  val_accuracy:0.5241,  val_loss:0.9744,  \n",
      "....................................................................................................\n",
      "Epoch: 600, accuracy:0.5391,  loss:0.9642,  val_accuracy:0.5241,  val_loss:0.9718,  \n",
      "....................................................................................................\n",
      "Epoch: 700, accuracy:0.5378,  loss:0.9641,  val_accuracy:0.5353,  val_loss:0.9702,  \n",
      "....................................................................................................\n",
      "Epoch: 800, accuracy:0.5436,  loss:0.9614,  val_accuracy:0.5218,  val_loss:0.9713,  \n",
      "....................................................................................................\n",
      "Epoch: 900, accuracy:0.5418,  loss:0.9605,  val_accuracy:0.5263,  val_loss:0.9694,  \n",
      "....................................................................................................\n",
      "Epoch: 1000, accuracy:0.5429,  loss:0.9586,  val_accuracy:0.5263,  val_loss:0.9693,  \n",
      "....................................................................................................\n",
      "Epoch: 1100, accuracy:0.5404,  loss:0.9589,  val_accuracy:0.5211,  val_loss:0.9700,  \n",
      "...Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 33)                1122      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 66)                2244      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 55)                3685      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 44)                2464      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 33)                1485      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 22)                748       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 11)                253       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 96        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 12,124\n",
      "Trainable params: 12,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, accuracy:0.4588,  loss:1.0796,  val_accuracy:0.4692,  val_loss:1.0630,  \n",
      "....................................................................................................\n",
      "Epoch: 100, accuracy:0.5214,  loss:0.9804,  val_accuracy:0.5466,  val_loss:0.9615,  \n",
      "....................................................................................................\n",
      "Epoch: 200, accuracy:0.5252,  loss:0.9748,  val_accuracy:0.5421,  val_loss:0.9648,  \n",
      "....................................................................................................\n",
      "Epoch: 300, accuracy:0.5310,  loss:0.9662,  val_accuracy:0.5556,  val_loss:0.9563,  \n",
      "....................................................................................................\n",
      "Epoch: 400, accuracy:0.5359,  loss:0.9616,  val_accuracy:0.5526,  val_loss:0.9592,  \n",
      "....................................................................................................\n",
      "Epoch: 500, accuracy:0.5369,  loss:0.9582,  val_accuracy:0.5519,  val_loss:0.9583,  \n",
      "................................................................................"
     ]
    }
   ],
   "source": [
    "# 2nd Attempt\n",
    "# Jupyter notebook\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128*8\n",
    "EPOCHS=10000\n",
    "validation_split = 0.2\n",
    "size_histories = {}\n",
    "\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H1-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 2 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H2-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 3 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H3-F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "### 4 Hidden Layers:\n",
    "#### High Amount of Neurons (H):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(21, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(29, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-H = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(33, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Medium Amount of Neurons (M):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(14, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-M = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Low Amount of Neurons (L):\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(4, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-L = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(8, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "#### Funnel Architecture:\n",
    "##### Model01:\n",
    "\n",
    "model01-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(13, activation='relu',input_shape=(train_X01.shape[1],)), # 13 features\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(10, activation='relu'),\n",
    "  layers.Dense(7, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model02:\n",
    "\n",
    "model02-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(21, activation='relu',input_shape=(train_X02.shape[1],)), # 21 features\n",
    "  layers.Dense(18, activation='relu'),\n",
    "  layers.Dense(13, activation='relu'),\n",
    "  layers.Dense(9, activation='relu'),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model03:\n",
    "\n",
    "model03-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(29, activation='relu',input_shape=(train_X03.shape[1],)), # 29 features\n",
    "  layers.Dense(22, activation='relu'),\n",
    "  layers.Dense(16, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model04:\n",
    "\n",
    "model04-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(25, activation='relu',input_shape=(train_X04.shape[1],)), # 25 features\n",
    "  layers.Dense(20, activation='relu'),\n",
    "  layers.Dense(15, activation='relu'),\n",
    "  layers.Dense(11, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "##### Model05:\n",
    "\n",
    "model05-H4-F = tf.keras.Sequential([\n",
    "  layers.Dense(33, activation='relu',input_shape=(train_X05.shape[1],)), # 33 features\n",
    "  layers.Dense(25, activation='relu'),\n",
    "  layers.Dense(19, activation='relu'),\n",
    "  layers.Dense(12, activation='relu'),\n",
    "  layers.Dense(6, activation='relu'),\n",
    "  layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# H1-H\n",
    "size_histories['model01-H1-H'] = compile_and_fit(model01-H1-H, 'model01-H1-H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H1-H'] = compile_and_fit(model02-H1-H, 'model02-H1-H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H1-H'] = compile_and_fit(model03-H1-H, 'model03-H1-H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H1-H'] = compile_and_fit(model04-H1-H, 'model04-H1-H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H1-H'] = compile_and_fit(model05-H1-H, 'model05-H1-H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1-M\n",
    "size_histories['model01-H1-M'] = compile_and_fit(model01-H1-M, 'model01-H1-M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H1-M'] = compile_and_fit(model02-H1-M, 'model02-H1-M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H1-M'] = compile_and_fit(model03-H1-M, 'model03-H1-M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H1-M'] = compile_and_fit(model04-H1-M, 'model04-H1-M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H1-M'] = compile_and_fit(model05-H1-M, 'model05-H1-M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H1-L\n",
    "size_histories['model01-H1-L'] = compile_and_fit(model01-H1-L, 'model01-H1-L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H1-L'] = compile_and_fit(model02-H1-L, 'model02-H1-L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H1-L'] = compile_and_fit(model03-H1-L, 'model03-H1-L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H1-L'] = compile_and_fit(model04-H1-L, 'model04-H1-L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H1-L'] = compile_and_fit(model05-H1-L, 'model05-H1-L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2-H\n",
    "size_histories['model01-H2-H'] = compile_and_fit(model01-H2-H, 'model01-H2-H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H2-H'] = compile_and_fit(model02-H2-H, 'model02-H2-H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H2-H'] = compile_and_fit(model03-H2-H, 'model03-H2-H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H2-H'] = compile_and_fit(model04-H2-H, 'model04-H2-H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H2-H'] = compile_and_fit(model05-H2-H, 'model05-H2-H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2-M\n",
    "size_histories['model01-H2-M'] = compile_and_fit(model01-H2-M, 'model01-H2-M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H2-M'] = compile_and_fit(model02-H2-M, 'model02-H2-M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H2-M'] = compile_and_fit(model03-H2-M, 'model03-H2-M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H2-M'] = compile_and_fit(model04-H2-M, 'model04-H2-M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H2-M'] = compile_and_fit(model05-H2-M, 'model05-H2-M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H2-L\n",
    "size_histories['model01-H2-L'] = compile_and_fit(model01-H2-L, 'model01-H2-L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H2-L'] = compile_and_fit(model02-H2-L, 'model02-H2-L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H2-L'] = compile_and_fit(model03-H2-L, 'model03-H2-L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H2-L'] = compile_and_fit(model04-H2-L, 'model04-H2-L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H2-L'] = compile_and_fit(model05-H2-L, 'model05-H2-L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3-H\n",
    "size_histories['model01-H3-H'] = compile_and_fit(model01-H3-H, 'model01-H3-H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H3-H'] = compile_and_fit(model02-H3-H, 'model02-H3-H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H3-H'] = compile_and_fit(model03-H3-H, 'model03-H3-H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H3-H'] = compile_and_fit(model04-H3-H, 'model04-H3-H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H3-H'] = compile_and_fit(model05-H3-H, 'model05-H3-H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3-M\n",
    "size_histories['model01-H3-M'] = compile_and_fit(model01-H3-M, 'model01-H3-M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H3-M'] = compile_and_fit(model02-H3-M, 'model02-H3-M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H3-M'] = compile_and_fit(model03-H3-M, 'model03-H3-M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H3-M'] = compile_and_fit(model04-H3-M, 'model04-H3-M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H3-M'] = compile_and_fit(model05-H3-M, 'model05-H3-M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3-L\n",
    "size_histories['model01-H3-L'] = compile_and_fit(model01-H3-L, 'model01-H3-L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H3-L'] = compile_and_fit(model02-H3-L, 'model02-H3-L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H3-L'] = compile_and_fit(model03-H3-L, 'model03-H3-L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H3-L'] = compile_and_fit(model04-H3-L, 'model04-H3-L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H3-L'] = compile_and_fit(model05-H3-L, 'model05-H3-L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H3-F\n",
    "size_histories['model01-H3-F'] = compile_and_fit(model01-H3-F, 'model01-H3-F', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H3-F'] = compile_and_fit(model02-H3-F, 'model02-H3-F', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H3-F'] = compile_and_fit(model03-H3-F, 'model03-H3-F', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H3-F'] = compile_and_fit(model04-H3-F, 'model04-H3-F', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H3-F'] = compile_and_fit(model05-H3-F, 'model05-H3-F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4-H\n",
    "size_histories['model01-H4-H'] = compile_and_fit(model01-H4-H, 'model01-H4-H', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H4-H'] = compile_and_fit(model02-H4-H, 'model02-H4-H', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H4-H'] = compile_and_fit(model03-H4-H, 'model03-H4-H', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H4-H'] = compile_and_fit(model04-H4-H, 'model04-H4-H', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H4-H'] = compile_and_fit(model05-H4-H, 'model05-H4-H', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4-M\n",
    "size_histories['model01-H4-M'] = compile_and_fit(model01-H4-M, 'model01-H4-M', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H4-M'] = compile_and_fit(model02-H4-M, 'model02-H4-M', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H4-M'] = compile_and_fit(model03-H4-M, 'model03-H4-M', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H4-M'] = compile_and_fit(model04-H4-M, 'model04-H4-M', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H4-M'] = compile_and_fit(model05-H4-M, 'model05-H4-M', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4-L\n",
    "size_histories['model01-H4-L'] = compile_and_fit(model01-H4-L, 'model01-H4-L', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H4-L'] = compile_and_fit(model02-H4-L, 'model02-H4-L', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H4-L'] = compile_and_fit(model03-H4-L, 'model03-H4-L', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H4-L'] = compile_and_fit(model04-H4-L, 'model04-H4-L', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H4-L'] = compile_and_fit(model05-H4-L, 'model05-H4-L', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "\n",
    "# H4-F\n",
    "size_histories['model01-H4-F'] = compile_and_fit(model01-H4-F, 'model01-H4-F', train_X01, train_y01, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model02-H4-F'] = compile_and_fit(model02-H4-F, 'model02-H4-F', train_X02, train_y02, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model03-H4-F'] = compile_and_fit(model03-H4-F, 'model03-H4-F', train_X03, train_y03, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model04-H4-F'] = compile_and_fit(model04-H4-F, 'model04-H4-F', train_X04, train_y04, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n",
    "size_histories['model05-H4-F'] = compile_and_fit(model05-H4-F, 'model05-H4-F', train_X05, train_y05, validation_split=validation_split,batch_size=BATCH_SIZE,max_epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "1DwuhGCJH2yL",
    "outputId": "13ba4f8a-0516-4937-d37a-8b0130fc5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9784467357591566\n",
      "Test Accuracy: 0.5393474\n",
      "#####\n",
      "Test Score: 0.9985063346949491\n",
      "Test Accuracy: 0.5113636\n",
      "#####\n",
      "Test Score: 0.9796081943945452\n",
      "Test Accuracy: 0.5255682\n",
      "#####\n",
      "Test Score: 0.970786578314645\n",
      "Test Accuracy: 0.5228571\n",
      "#####\n",
      "Test Score: 1.013617993082319\n",
      "Test Accuracy: 0.52\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# H1-H\n",
    "score = load_model('../model/model01-H1-H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01-H1-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H1-H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H1-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H1-H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H1-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H1-H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H1-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H1-H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H1-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1-M\n",
    "score = load_model('../model/model01-H1-M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01-H1-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H1-M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H1-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H1-M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H1-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H1-M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H1-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H1-M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H1-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H1-L\n",
    "score = load_model('../model/model01-H1-L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01-H1-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H1-L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H1-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H1-L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H1-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H1-L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H1-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H1-L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H1-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2-H\n",
    "score = load_model('../model/model01-H2-H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01-H2-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H2-H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H2-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H2-H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H2-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H2-H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H2-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H2-H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H2-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2-M\n",
    "score = load_model('../model/model01-H2-M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model01-H2-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H2-M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H2-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H2-M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H2-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H2-M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H2-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H2-M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H2-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H2-L\n",
    "score = load_model('../model/model01-H2-L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H2-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H2-L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H2-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H2-L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H2-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H2-L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H2-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H2-L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H2-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3-H\n",
    "score = load_model('../model/model01-H3-H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H3-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H3-H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H3-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H3-H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H3-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H3-H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H3-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H3-H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H3-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3-M\n",
    "score = load_model('../model/model01-H3-M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H3-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H3-M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H3-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H3-M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H3-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H3-M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H3-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H3-M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H3-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3-L\n",
    "score = load_model('../model/model01-H3-L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H3-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H3-L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H3-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H3-L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H3-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H3-L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H3-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H3-L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H3-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H3-F\n",
    "score = load_model('../model/model01-H3-F.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H3-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H3-F.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H3-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H3-F.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H3-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H3-F.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H3-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H3-F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H3-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4-H\n",
    "score = load_model('../model/model01-H4-H.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H4-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H4-H.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H4-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H4-H.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H4-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H4-H.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H4-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H4-H.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H4-H\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4-M\n",
    "score = load_model('../model/model01-H4-M.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H4-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H4-M.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H4-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H4-M.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H4-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H4-M.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H4-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H4-M.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H4-M\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4-L\n",
    "score = load_model('../model/model01-H4-L.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H4-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H4-L.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H4-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H4-L.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H4-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H4-L.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H4-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H4-L.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H4-L\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "# H4-F\n",
    "score = load_model('../model/model01-H4-F.h5').evaluate(test_X01, test_y01, verbose=3)\n",
    "print(\"model02-H4-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model02-H4-F.h5').evaluate(test_X02, test_y02, verbose=3)\n",
    "print(\"model02-H4-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model03-H4-F.h5').evaluate(test_X03, test_y03, verbose=3)\n",
    "print(\"model03-H4-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model04-H4-F.h5').evaluate(test_X04, test_y04, verbose=3)\n",
    "print(\"model04-H4-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")\n",
    "\n",
    "score = load_model('../model/model05-H4-F.h5').evaluate(test_X05, test_y05, verbose=3)\n",
    "print(\"model05-H4-F\")\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])\n",
    "print(\"#####\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab-nn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
